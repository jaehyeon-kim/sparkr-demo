---
title: "SparkR Demo"
author: Jaehyeon kim
date: March 14, 2018
output: slidy_presentation
---

# Data manipulation - _local DF_

```{r titanic_01, eval=FALSE}
Sys.setenv('JAVA_HOME'='/usr/lib/jvm/java-8-openjdk-amd64')
Sys.setenv('HADOOP_HOME'='/usr/local/hadoop-2.8.2')
Sys.setenv('SPARK_HOME'='/usr/local/spark-2.2.1')

library(magrittr); library(tibble); library(dplyr)
library(SparkR, lib.loc=file.path(Sys.getenv('SPARK_HOME'),'R', 'lib'))
sparkR.session(master = 'spark://master:7077', appName = 'titanic demo',
               sparkConfig = list(spark.driver.memory = '2g'))

titanic <- read.csv('titanic.csv', stringsAsFactors = FALSE)
rec <- nrow(titanic)
df <- as.DataFrame(titanic)
tdf <- as.tibble(titanic)

## quick check
str(df); printSchema(df)
head(df); summary(df) %>% head(10)

## different classes
df %>% class() # SparkDataFrame
df %>% head() %>% class() # data.frame
df %>% collect() # SparkDataFrame to data.frame
```

# Data manipulation - _select, filter..._

```{r titanic_02, eval=FALSE}
#### selecting rows, columns
df %>% select(df$survived) %>% head()
df %>% select(expr('survived')) %>% head()
df %>% select('class', 'survived') %>% head()

tdf %>% dplyr::select(class, survived) %>% head()

df %>% filter('survived == "yes" and age == "child"') %>% head()
df %>% filter(df$survived == 'yes' & df$age == 'child') %>% head()

tdf %>% dplyr::filter(survived == 'yes' & age == 'child') %>% head()

## expressions
df$survived # Column survived
expr('survived') # Column survived
'survived' # string
```

- many function names are same to _dplyr_
    + use `::` for calling them
- expressions are interchangeable but not always - see _dapply_ section
- `expr()` is more expressive - see ML section

# Data manipulation - _group_by, mutate ..._

```{r titanic_03, eval=FALSE}
#### grouping, aggregation
df %>% group_by('class', 'age') %>%
  summarize(count = n(expr('survived'))) %>%
  arrange('class', 'age') %>% head(7)

tdf %>% dplyr::group_by(class, age) %>%
  dplyr::summarise(count = n()) %>% head(7)

#### operating on columns
tmp <- df %>% group_by('class', 'age') %>%
  summarize(count = n(expr('survived')))
tmp %>% mutate(prop = expr('count') / rec) %>% 
  arrange('class', 'age') %>% head(10)

tdf %>% dplyr::group_by(class, age) %>%
  dplyr::summarise(count = n()) %>% 
  dplyr::mutate(prop = count / rec) %>%
  head(10)
```

- want to obtain _count_ and _proportion_ by _class_ and _age_
- unlike _dplyr_, cannot refer to column that's created in a chain
- 4 ways to improve in subsequent slides

# Data manipulation - _dapply_

```{r titanic_04, eval=FALSE}
## dapply, dapplyCollect
schema <- structType(
  structField('class', 'string'),
  structField('age', 'string'),
  structField('count', 'double'), # not integer
  structField('prop', 'double')
)

fn <- function(x) {
  cbind(x, x$count / rec) # expr() not working
}

# may take more time but no temporary DF
df %>% group_by('class', 'age') %>%
  summarize(count = n(expr('survived'))) %>%
  dapply(fn, schema) %>%
  arrange('class', 'age') %>% head(10)
```

- `dapply()` - apply a function to each partition of a _SparkDataFrame_
- note `expr()`/_string_ don't work in the function
- will be more efficient if applied to a grouped data

# Data manipulation - _gapply_

```{r titanic_05, eval=FALSE}
## gapply, gapplyCollect
schema <- structType(
  structField('class', 'string'),
  structField('age', 'string'),
  structField('count', 'integer'),
  structField('prop', 'double')
)

fn <- function(key, x) {
  data.frame(key, nrow(x), nrow(x)/rec, stringsAsFactors = FALSE)
}

df %>% gapply(cols = c('class', 'age'), func = fn, schema = schema) %>%
  arrange('class', 'age') %>% head(10)
```

- `dapply()` - apply a function to each partition of a grouped _SparkDataFrame_
- note `nrow()` is not base R function

# Data manipulation - _SQL_

```{r titanic_06, eval=FALSE}
#### sql queries
createOrReplaceTempView(df, 'titanic_tbl')

`%++%` <- function(a, b) paste(a, b)
qry <- '
  SELECT class, age, count(*) as count, count(*) /' %++% 
          format(round(rec, 1), nsmall = 1) %++% 'as prop' %++%
  'FROM titanic_tbl' %++%
  'group by class, age' %++%
  'order by class, age'

sql(qry) %>% head(10)
```

- SQL can be applied after creating/replacing a temporary view
- [window functions](https://databricks.com/blog/2015/07/15/introducing-window-functions-in-spark-sql.html) introduced in Spark 2
- do we need [HiveQL](https://cwiki.apache.org/confluence/display/Hive/LanguageManual)?

# Data manipulation - _spark.lapply_

```{r titanic_07, eval=FALSE}
#### spark.lapply
discnt <- tdf %>% dplyr::distinct(class, age)
lst <- lapply(1:nrow(discnt), function(i) {
  cls <- discnt[i, 1] %>% unlist()
  ag <- discnt[i, 2] %>% unlist()
  list(dat = tdf %>% dplyr::filter(class == cls & age == ag),
       rec = rec)
})

fn <- function(elem) {
  library(magrittr)
  elem$dat %>% dplyr::group_by(class, age) %>%
    dplyr::summarise(count = n(), prop = count / elem$rec)
}

spark.lapply(lst, fn) %>%
  bind_rows() %>%
  dplyr::arrange(class, age) %>%
  head(10)
```

- run non-SparkR functions over a list of elements and distributes the computations with Spark
- limitation - results of all the computations should fit in a single machine

# Machine Learning - _in progress_

```{r flight_01, eval=FALSE}
      date dep_time arr_time unique_carrier air_time arr_delay dep_delay origin dest distance cancelled
1 2007/1/1     1232     1341             WN       54         1         7    SMF  ONT      389         0
2 2007/1/1     1918     2043             WN       74         8        13    SMF  PDX      479         0
3 2007/1/1     2206     2334             WN       73        34        36    SMF  PDX      479         0
4 2007/1/1     1230     1356             WN       75        26        30    SMF  PDX      479         0
5 2007/1/1      831      957             WN       74        -3         1    SMF  PDX      479         0
6 2007/1/1     1430     1553             WN       74         3        10    SMF  PDX      479         0
```

<style>
.column-left{
  float: left;
  width: 50%;
  text-align: left;
}
.column-right{
  float: right;
  width: 50%;
  text-align: left;
}
</style>

<div class="column-left">
+ **date** date (yyyy/mm/dd)  
+ **dep_time** departure time (hhmm)
+ **arr_time** arrival time (hhmm)
+ **unique_carrier** carrier code
+ **air_time** flight time
+ **arr_delay** arrival delay
</div>
<div class="column-right">
+ **dep_delay** departure delay
+ **origin** origin
+ **dest** destination
+ **distance** distance
+ **cancelled** is cancelled?

see [source]()
</div>

